
@book{Zanden2009,
title = {The Long Road to the Industrial Revolution : The European Economy in a Global Perspective, 1000-1800},
author = {Jan van Zanden},
year = {2009},
publisher = {Brill}
}

@book{Sher2006,
year={2006},
publisher= {The University of Chicago Press},
author={Richard Sher},
title = {{The Enlightenment and the Book : Scottish Authors and
Their Publishers in Eighteenth-Century Britain, Ireland, and
America}}
}

@inbook{Hill2016,
      author = "Alexandra Hill",
      title = "Lost Print in England: Entries in the Stationers’ Company Register, 1557–1640",
      booktitle = "Lost Books. Reconstructing the Print World of Pre-Industrial Europe",
      year = "2016",
      publisher = "Brill",
      address = "Leiden, The Netherlands",
      isbn = "9789004311824",
      pages = "144-159"
}

@article{Lahti2019,
author = {Leo Lahti and Jani Marjanen and Hege Roivainen and Mikko Tolonen},
title = {Bibliographic Data Science and the History of the Book (c. 1500–1800)},
journal = {Cataloging \& Classification Quarterly},
volume = {57},
number = {1},
pages = {5-23},
year  = {2019},
publisher = {Routledge},
doi = {10.1080/01639374.2018.1543747}
}

@inproceedings{Hill2019,
       booktitle = {Digital Humanities in the Nordic Countries},
           title = {Reconstructing Intellectual Networks: From the ESTC?s bibliographic metadata to historical material},
          author = {Mark J Hill and Ville Vaara and Tanja S{\"a}ily and Leo Lahti and Mikko Tolonen},
            year = {2019},
         journal = {Proceedings of the Digital Humanities in the Nordic Countries},
        keywords = {Digital History; Social Network Analysis; Metadata; Book History; Bibliographic Data; Intellectual History},
             url = {https://kar.kent.ac.uk/90141/},
        abstract = {This paper demonstrates the use of the ESTC as a representation of material history through the extraction and parsing of its data in a way which allows it to be used in social network analysis. In doing this it makes two contributions. The first is methodological, outlining how such a transformation of data is possible. The second is historical, by demonstrating how this data can be used to support historical claims.}
}


@article{Domenico2013,
author = {M. De Domenico and A. Lima and P. Mougel and M. Musolesi},
title = {The Anatomy of a Scientific Rumor},
journal = {Scientific Reports},
volume = {2980},
number = {3},
pages = {5-23},
year  = {2013},
doi = {https://doi.org/10.1038/srep02980}
}

@article{Shahi2021,
title = {An exploratory study of COVID-19 misinformation on Twitter},
journal = {Online Social Networks and Media},
volume = {22},
pages = {100104},
year = {2021},
issn = {2468-6964},
doi = {https://doi.org/10.1016/j.osnem.2020.100104},
url = {https://www.sciencedirect.com/science/article/pii/S2468696420300458},
author = {Gautam Kishore Shahi and Anne Dirkson and Tim A. Majchrzak},
keywords = {Misinformation, Twitter, Social media, COVID-19, Fake news, Coronavirus, Diffusion of information},
abstract = {During the COVID-19 pandemic, social media has become a home ground for misinformation. To tackle this infodemic, scientific oversight, as well as a better understanding by practitioners in crisis management, is needed. We have conducted an exploratory study into the propagation, authors and content of misinformation on Twitter around the topic of COVID-19 in order to gain early insights. We have collected all tweets mentioned in the verdicts of fact-checked claims related to COVID-19 by over 92 professional fact-checking organisations between January and mid-July 2020 and share this corpus with the community. This resulted in 1500 tweets relating to 1274 false and 226 partially false claims, respectively. Exploratory analysis of author accounts revealed that the verified twitter handle(including Organisation/celebrity) are also involved in either creating(new tweets) or spreading(retweet) the misinformation. Additionally, we found that false claims propagate faster than partially false claims. Compare to a background corpus of COVID-19 tweets, tweets with misinformation are more often concerned with discrediting other information on social media. Authors use less tentative language and appear to be more driven by concerns of potential harm to others. Our results enable us to suggest gaps in the current scientific coverage of the topic as well as propose actions for authorities and social media users to counter misinformation.}
}


@book{Christen2012,
author = {Christen, Peter},
title = {Data Matching: Concepts and Techniques for Record Linkage, Entity Resolution, and Duplicate Detection},
year = {2012},
isbn = {3642311636},
publisher = {Springer Publishing Company, Incorporated},
abstract = {Data matching (also known as record or data linkage, entity resolution, object identification, or field matching) is the task of identifying, matching and merging records that correspond to the same entities from several databases or even within one database. Based on research in various domains including applied statistics, health informatics, data mining, machine learning, artificial intelligence, database management, and digital libraries, significant advances have been achieved over the last decade in all aspects of the data matching process, especially on how to improve the accuracy of data matching, and its scalability to large databases. Peter Christens book is divided into three parts: Part I, Overview, introduces the subject by presenting several sample applications and their special challenges, as well as a general overview of a generic data matching process. Part II, Steps of the Data Matching Process, then details its main steps like pre-processing, indexing, field and record comparison, classification, and quality evaluation. Lastly, part III, Further Topics, deals with specific aspects like privacy, real-time matching, or matching unstructured data. Finally, it briefly describes the main features of many research and open source systems available today. By providing the reader with a broad range of data matching concepts and techniques and touching on all aspects of the data matching process, this book helps researchers as well as students specializing in data quality or data matching aspects to familiarize themselves with recent research advances and to identify open research challenges in the area of data matching. To this end, each chapter of the book includes a final section that provides pointers to further background and research material. Practitioners will better understand the current state of the art in data matching as well as the internal workings and limitations of current systems. Especially, they will learn that it is often not feasible to simply implement an existing off-the-shelf data matching system without substantial adaption and customization. Such practical considerations are discussed for each of the major steps in the data matching process.}
}

  


@book{Zanden2009,
title = {The Long Road to the Industrial Revolution : The European Economy in a Global Perspective, 1000-1800},
author = {Jan van Zanden},
year = {2009},
publisher = {Brill}
}

@book{Sher2006,
year={2006},
publisher= {The University of Chicago Press},
author={Richard Sher},
title = {{The Enlightenment and the Book : Scottish Authors and
Their Publishers in Eighteenth-Century Britain, Ireland, and
America}}
}

@inbook{Hill2016,
      author = "Alexandra Hill",
      title = "Lost Print in England: Entries in the Stationers’ Company Register, 1557–1640",
      booktitle = "Lost Books. Reconstructing the Print World of Pre-Industrial Europe",
      year = "2016",
      publisher = "Brill",
      address = "Leiden, The Netherlands",
      isbn = "9789004311824",
      pages = "144-159"
}

@article{Lahti2019,
author = {Leo Lahti and Jani Marjanen and Hege Roivainen and Mikko Tolonen},
title = {Bibliographic Data Science and the History of the Book (c. 1500–1800)},
journal = {Cataloging \& Classification Quarterly},
volume = {57},
number = {1},
pages = {5-23},
year  = {2019},
publisher = {Routledge},
doi = {10.1080/01639374.2018.1543747}
}

@inproceedings{Hill2019,
       booktitle = {Digital Humanities in the Nordic Countries},
           title = {Reconstructing Intellectual Networks: From the ESTC?s bibliographic metadata to historical material},
          author = {Mark J Hill and Ville Vaara and Tanja S{\"a}ily and Leo Lahti and Mikko Tolonen},
            year = {2019},
         journal = {Proceedings of the Digital Humanities in the Nordic Countries},
        keywords = {Digital History; Social Network Analysis; Metadata; Book History; Bibliographic Data; Intellectual History},
             url = {https://kar.kent.ac.uk/90141/},
        abstract = {This paper demonstrates the use of the ESTC as a representation of material history through the extraction and parsing of its data in a way which allows it to be used in social network analysis. In doing this it makes two contributions. The first is methodological, outlining how such a transformation of data is possible. The second is historical, by demonstrating how this data can be used to support historical claims.}
}


@article{Domenico2013,
author = {M. De Domenico and A. Lima and P. Mougel and M. Musolesi},
title = {The Anatomy of a Scientific Rumor},
journal = {Scientific Reports},
volume = {2980},
number = {3},
pages = {5-23},
year  = {2013},
doi = {https://doi.org/10.1038/srep02980}
}

@article{Shahi2021,
title = {An exploratory study of COVID-19 misinformation on Twitter},
journal = {Online Social Networks and Media},
volume = {22},
pages = {100104},
year = {2021},
issn = {2468-6964},
doi = {https://doi.org/10.1016/j.osnem.2020.100104},
url = {https://www.sciencedirect.com/science/article/pii/S2468696420300458},
author = {Gautam Kishore Shahi and Anne Dirkson and Tim A. Majchrzak},
keywords = {Misinformation, Twitter, Social media, COVID-19, Fake news, Coronavirus, Diffusion of information},
abstract = {During the COVID-19 pandemic, social media has become a home ground for misinformation. To tackle this infodemic, scientific oversight, as well as a better understanding by practitioners in crisis management, is needed. We have conducted an exploratory study into the propagation, authors and content of misinformation on Twitter around the topic of COVID-19 in order to gain early insights. We have collected all tweets mentioned in the verdicts of fact-checked claims related to COVID-19 by over 92 professional fact-checking organisations between January and mid-July 2020 and share this corpus with the community. This resulted in 1500 tweets relating to 1274 false and 226 partially false claims, respectively. Exploratory analysis of author accounts revealed that the verified twitter handle(including Organisation/celebrity) are also involved in either creating(new tweets) or spreading(retweet) the misinformation. Additionally, we found that false claims propagate faster than partially false claims. Compare to a background corpus of COVID-19 tweets, tweets with misinformation are more often concerned with discrediting other information on social media. Authors use less tentative language and appear to be more driven by concerns of potential harm to others. Our results enable us to suggest gaps in the current scientific coverage of the topic as well as propose actions for authorities and social media users to counter misinformation.}
}


@book{Christen2012,
author = {Christen, Peter},
title = {Data Matching: Concepts and Techniques for Record Linkage, Entity Resolution, and Duplicate Detection},
year = {2012},
isbn = {3642311636},
publisher = {Springer Publishing Company, Incorporated},
abstract = {Data matching (also known as record or data linkage, entity resolution, object identification, or field matching) is the task of identifying, matching and merging records that correspond to the same entities from several databases or even within one database. Based on research in various domains including applied statistics, health informatics, data mining, machine learning, artificial intelligence, database management, and digital libraries, significant advances have been achieved over the last decade in all aspects of the data matching process, especially on how to improve the accuracy of data matching, and its scalability to large databases. Peter Christens book is divided into three parts: Part I, Overview, introduces the subject by presenting several sample applications and their special challenges, as well as a general overview of a generic data matching process. Part II, Steps of the Data Matching Process, then details its main steps like pre-processing, indexing, field and record comparison, classification, and quality evaluation. Lastly, part III, Further Topics, deals with specific aspects like privacy, real-time matching, or matching unstructured data. Finally, it briefly describes the main features of many research and open source systems available today. By providing the reader with a broad range of data matching concepts and techniques and touching on all aspects of the data matching process, this book helps researchers as well as students specializing in data quality or data matching aspects to familiarize themselves with recent research advances and to identify open research challenges in the area of data matching. To this end, each chapter of the book includes a final section that provides pointers to further background and research material. Practitioners will better understand the current state of the art in data matching as well as the internal workings and limitations of current systems. Especially, they will learn that it is often not feasible to simply implement an existing off-the-shelf data matching system without substantial adaption and customization. Such practical considerations are discussed for each of the major steps in the data matching process.}
}

@Manual{Wickham2022,
  title = {stringr: Simple, Consistent Wrappers for Common String Operations},
  author = {Hadley Wickham},
  year = {2022},
  note = {http://stringr.tidyverse.org,
https://github.com/tidyverse/stringr},
}
  



